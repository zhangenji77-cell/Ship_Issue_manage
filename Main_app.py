import streamlit as st
import pandas as pd
from datetime import datetime
import sqlalchemy
from sqlalchemy import text
import export_utils

# --- 1. é¡µé¢åŸºæœ¬é…ç½® ---
st.set_page_config(
    page_title="èˆ¹èˆ¶é—®é¢˜äº‘å¡«æŠ¥ç³»ç»Ÿ",
    layout="wide",
    page_icon="ğŸš¢",
    initial_sidebar_state="expanded"
)

st.title("ğŸš¢ èˆ¹èˆ¶é—®é¢˜å‘¨åº¦å¡«æŠ¥ç³»ç»Ÿ")
st.caption("å½“å‰èŠ‚ç‚¹ï¼šSingapore (ap-southeast-1) | ç¯å¢ƒï¼šæé€Ÿç¼“å­˜æ¨¡å¼")


# --- 2. æ•°æ®åº“å¼•æ“ç¼“å­˜ (ä¿æŒè¿æ¥ï¼Œé¿å…é‡å¤æ¡æ‰‹) ---
@st.cache_resource
def get_engine():
    try:
        db_url = st.secrets["postgres_url"]
        if db_url.startswith("postgres://"):
            db_url = db_url.replace("postgres://", "postgresql://", 1)

        return sqlalchemy.create_engine(
            db_url,
            poolclass=sqlalchemy.pool.NullPool,  # ç¦ç”¨æœ¬åœ°æ± ï¼Œå®Œå…¨äº¤ç»™ Supabase æ± ç®¡ç†
            connect_args={
                "sslmode": "require",
                "connect_timeout": 5
            }
        )
    except Exception as e:
        st.error(f"å¼•æ“åˆ›å»ºå¤±è´¥: {e}")
        return None


# --- 3. æ•°æ®å±‚ï¼šæé€Ÿç¼“å­˜é€»è¾‘ ---
@st.cache_data(ttl=600)  # ç¼“å­˜10åˆ†é’Ÿï¼Œ10åˆ†é’Ÿå†…åˆ·æ–°ç½‘é¡µç§’å¼€
def fetch_initial_data():
    """ä¸€æ¬¡æ€§æŠ“å–æ‰€æœ‰ç®¡ç†äººå’Œèˆ¹èˆ¶åŸºç¡€æ•°æ®ï¼Œå‡å°‘ç½‘ç»œå¾€è¿”æ¬¡æ•°"""
    engine = get_engine()
    if not engine: return pd.DataFrame()

    with engine.connect() as conn:
        # ä¸€æ¬¡æ€§å…³è”æŸ¥è¯¢
        query = text("SELECT id, ship_name, manager_name FROM ships ORDER BY manager_name, ship_name")
        return pd.read_sql_query(query, conn)


def fetch_last_report(ship_id):
    """å®æ—¶æŠ“å–æŒ‡å®šèˆ¹èˆ¶çš„ä¸Šä¸€æ¡è®°å½•ï¼ˆä¸ç¼“å­˜ï¼Œç¡®ä¿å³æ—¶å¯è§ï¼‰"""
    engine = get_engine()
    with engine.connect() as conn:
        query = text("""
            SELECT this_week_issue FROM reports 
            WHERE ship_id = :sid 
            ORDER BY report_date DESC LIMIT 1
        """)
        res = conn.execute(query, {"sid": ship_id}).fetchone()
        return res[0] if res else "ï¼ˆè¯¥èˆ¹æš‚æ— å†å²è®°å½•ï¼‰"


# --- 4. ä¸šåŠ¡é€»è¾‘ä¸»ä½“ ---

# 4.1 åŠ è½½åŸºç¡€æ•°æ®ï¼ˆç”±äºæœ‰ cache_dataï¼Œè¿™é‡Œæå¿«ï¼‰
all_ships_df = fetch_initial_data()

if all_ships_df.empty:
    st.warning("âš ï¸ æ•°æ®åº“è¿æ¥æ­£å¸¸ä½†æœªå‘ç°æ•°æ®ï¼Œè¯·æ£€æŸ¥ ships è¡¨ã€‚")
    st.stop()

# 4.2 ä¾§è¾¹æ ï¼šé€‰æ‹©ç®¡ç†äºº
manager_list = sorted(all_ships_df['manager_name'].unique().tolist())
current_user = st.sidebar.selectbox("ğŸ”‘ è¯·é€‰æ‹©æ‚¨çš„å§“å", ["--- è¯·é€‰æ‹© ---"] + manager_list)

if current_user != "--- è¯·é€‰æ‹© ---":
    st.header(f"æ¬¢è¿ï¼Œ{current_user}ã€‚")

    # 4.3 é€‰æ‹©èˆ¹èˆ¶ï¼ˆçº¯å†…å­˜è¿‡æ»¤ï¼Œ0å»¶è¿Ÿï¼‰
    my_ships = all_ships_df[all_ships_df['manager_name'] == current_user]
    selected_ship_name = st.selectbox("1. é€‰æ‹©è¦å¡«æŠ¥çš„èˆ¹èˆ¶", my_ships['ship_name'].tolist())
    ship_id = int(my_ships[my_ships['ship_name'] == selected_ship_name]['id'].iloc[0])

    st.divider()

    col1, col2 = st.columns([1, 1.2])

    with col1:
        st.subheader("ğŸ“Š å†å²è®°å½•å›æº¯")
        # ä»…é’ˆå¯¹é€‰ä¸­çš„èˆ¹è¿›è¡Œä¸€æ¬¡ç²¾å‡†æŸ¥è¯¢
        last_issue = fetch_last_report(ship_id)
        st.info(f"**è¯¥èˆ¹ä¸Šå‘¨è®°å½•çš„é—®é¢˜ï¼š**\n\n {last_issue}")

    with col2:
        st.subheader("ğŸ“ æœ¬å‘¨æ•°æ®å¡«æŠ¥")
        this_issue = st.text_area("2. æœ¬å‘¨èˆ¹èˆ¶é—®é¢˜", placeholder="è¯·è¯¦ç»†æè¿°æœ¬å‘¨å‘ç°çš„é—®é¢˜...", height=150)
        remark = st.text_input("3. å¤‡æ³¨ (é€‰å¡«)")

        if st.button("âœ… æäº¤å¹¶åŒæ­¥è‡³äº‘ç«¯", use_container_width=True):
            if this_issue:
                with st.spinner("æ­£åœ¨åŒæ­¥è‡³æ–°åŠ å¡æ•°æ®åº“..."):
                    engine = get_engine()
                    try:
                        with engine.begin() as conn:
                            conn.execute(
                                text(
                                    "INSERT INTO reports (ship_id, report_date, this_week_issue, remarks) VALUES (:sid, :dt, :issue, :rem)"),
                                {"sid": ship_id, "dt": datetime.now().date(), "issue": this_issue, "rem": remark}
                            )
                        st.success("æäº¤æˆåŠŸï¼æ•°æ®å·²å®æ—¶åŒæ­¥ã€‚")
                        st.balloons()
                        # é‡è¦ï¼šæäº¤åæ¸…é™¤æ•°æ®ç¼“å­˜ï¼Œç¡®ä¿ä¸‹æ¬¡åˆ·æ–°èƒ½çœ‹åˆ°æ–°è®°å½•
                        st.cache_data.clear()
                    except Exception as e:
                        st.error(f"æäº¤å¤±è´¥: {e}")
            else:
                st.warning("âš ï¸ è¯·è¾“å…¥é—®é¢˜å†…å®¹åå†æäº¤ã€‚")

# --- 5. æŠ¥è¡¨ç”Ÿæˆæ¨¡å— ---
st.divider()
st.header("ğŸ“‚ æŠ¥è¡¨ä¸ä¼šè®®ææ–™")
if st.button("ğŸ” ç”Ÿæˆæœ¬å‘¨æ±‡æ€»æŠ¥å‘Š", type="secondary"):
    with st.spinner("æ­£åœ¨æ•´ç†äº‘ç«¯æ±‡æ€»æ•°æ®..."):
        df_summary = export_utils.get_report_data()
        if not df_summary.empty:
            st.dataframe(df_summary, use_container_width=True)

            # ç”Ÿæˆä¸´æ—¶æ–‡ä»¶å¹¶æä¾›ä¸‹è½½
            excel_file = export_utils.generate_excel(df_summary, "èˆ¹èˆ¶æ±‡æ€».xlsx")
            ppt_file = export_utils.generate_ppt(df_summary, "å‘¨æŠ¥å±•ç¤º.pptx")

            c1, c2 = st.columns(2)
            with c1:
                with open(excel_file, "rb") as f:
                    st.download_button("ğŸ“¥ ä¸‹è½½ Excel è¡¨æ ¼", f, file_name=excel_file, use_container_width=True)
            with c2:
                with open(ppt_file, "rb") as f:
                    st.download_button("ğŸ“¥ ä¸‹è½½ PPT å¹»ç¯ç‰‡", f, file_name=ppt_file, use_container_width=True)
        else:
            st.info("ğŸ’¡ æ•°æ®åº“ä¸­æš‚æ— æœ¬å‘¨å¡«æŠ¥è®°å½•ã€‚")